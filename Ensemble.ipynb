{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python-MIP package version 1.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcos/Documents/Experiments/envs/crime/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklego.metrics import equal_opportunity_score\n",
    "from sklego.metrics import p_percent_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.utils.extmath import squared_norm\n",
    "from moopt.scalarization_interface import scalar_interface, single_interface, w_interface\n",
    "from moopt import monise\n",
    "import numpy as np\n",
    "import optuna, sklearn, sklearn.datasets\n",
    "from fair_models import coefficient_of_variation, MOOLogisticRegression, FindCLogisticRegression, FindCCLogisticRegression,FairScalarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "class SimpleVoting():\n",
    "    def __init__(self, estimators, voting='hard'):\n",
    "        self.estimators = estimators\n",
    "        self.voting = voting\n",
    "        self.classes_ = estimators[0][1].classes_\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.voting=='soft':\n",
    "            argmax = np.argmax(np.mean([m[1].predict_proba(X) for m in self.estimators],axis=0), axis=1)\n",
    "            y_pred = np.array([self.classes_[v] for v in argmax])\n",
    "        else:\n",
    "            y_pred = stats.mode([m[1].predict(X) for m in self.estimators],axis=0)[0][0]\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return sklearn.metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata= pd.read_csv(\"Datasets/german_credit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.drop(['Unnamed: 0', 'Purpose'], axis=1)\n",
    "mydata = mydata.dropna()\n",
    "\n",
    "mapping_Sex = {'male': 0, 'female': 1}\n",
    "mapping_Housing = {'free': 1, 'rent': 2, 'own': 3}\n",
    "mapping_Savings = {'little': 1, 'moderate': 2, 'quite rich': 3, 'rich': 4}\n",
    "mapping_Checking = {'little': 1, 'moderate': 2, 'rich': 3}\n",
    "mapping_Risk = {\"bad\": -1, \"good\": 1}\n",
    "\n",
    "numerical_data = mydata.replace({'Sex': mapping_Sex, 'Housing': mapping_Housing, 'Saving accounts': mapping_Savings,\n",
    "                'Checking account':mapping_Checking, 'Risk': mapping_Risk})\n",
    "\n",
    "X = numerical_data.drop(['Risk'], axis=1)\n",
    "\n",
    "y = numerical_data['Risk']\n",
    "\n",
    "random_seed = 2000#np.random.randint(0, 1000)\n",
    "random_seed2 = 2000#np.random.randint(0, 1000)\n",
    "\n",
    "X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=200, random_state = random_seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=100, random_state = random_seed2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file /home/marcos/gurobi.lic\n",
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "moo = monise(weightedScalar=FairScalarization(X_train, y_train, 'Sex'),\n",
    "             singleScalar=FairScalarization(X_train, y_train, 'Sex'),\n",
    "              nodeTimeLimit=2, targetSize=150,\n",
    "              targetGap=0, nodeGap=0.01, norm=False)\n",
    "\n",
    "moo.optimize()\n",
    "\n",
    "sols = []\n",
    "\n",
    "for solution in moo.solutionsList:\n",
    "    sols.append(solution.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble - All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_t = []\n",
    "for i in range(len(sols)):\n",
    "    models_t.append((\"Model \"+str(i),sols[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = SimpleVoting(estimators=models_t, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eclf1 = eclf1.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics - Train Data\n",
      "Acc:  0.6531531531531531\n",
      "Eq Opor:  0.9589490968801313\n",
      "P Perc:  0.9692961738308926\n",
      "Coev Var:  0.6761773706108338\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics - Train Data\")\n",
    "print(\"Acc: \", eclf1.score(X_train, y_train))\n",
    "print(\"Eq Opor: \", equal_opportunity_score(sensitive_column=\"Sex\")(eclf1, X_train, y_train))\n",
    "print(\"P Perc: \", p_percent_score(sensitive_column=\"Sex\")(eclf1, X_train))\n",
    "print(\"Coev Var: \", coefficient_of_variation(eclf1, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics - Val Data\n",
      "Acc:  0.68\n",
      "Eq Opor:  0.9890109890109889\n",
      "P Perc:  0.9629629629629629\n",
      "Coev Var:  0.6614940032155477\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics - Val Data\")\n",
    "print(\"Acc: \", eclf1.score(X_val, y_val))\n",
    "print(\"Eq Opor: \", equal_opportunity_score(sensitive_column=\"Sex\")(eclf1, X_val, y_val))\n",
    "print(\"P Perc: \", p_percent_score(sensitive_column=\"Sex\")(eclf1, X_val))\n",
    "print(\"Coev Var: \", coefficient_of_variation(eclf1, X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics - Test Data\n",
      "Acc:  0.61\n",
      "Eq Opor:  0.995967741935484\n",
      "P Perc:  0.9309523809523809\n",
      "Coev Var:  0.6775074858941582\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics - Test Data\")\n",
    "print(\"Acc: \", eclf1.score(X_test, y_test))\n",
    "print(\"Eq Opor: \", equal_opportunity_score(sensitive_column=\"Sex\")(eclf1, X_test, y_test))\n",
    "print(\"P Perc: \", p_percent_score(sensitive_column=\"Sex\")(eclf1, X_test))\n",
    "print(\"Coev Var: \", coefficient_of_variation(eclf1, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter dominated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominate(a, b):\n",
    "    sense = np.array([1, 1, 1, -1])\n",
    "    if all((sense*a)>=(sense*b)) and any((sense*a)>(sense*b)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcos/Documents/Experiments/envs/crime/lib/python3.7/site-packages/sklego/metrics.py:155: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  score = np.minimum(p_y1_z1 / p_y1_z0, p_y1_z0 / p_y1_z1)\n",
      "/home/marcos/Documents/Experiments/envs/crime/lib/python3.7/site-packages/sklego/metrics.py:79: RuntimeWarning: No samples with y_hat == 1 for Sex == 1, returning 0\n",
      "  RuntimeWarning,\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(len(sols)):\n",
    "    metrics.append((sols[i].score(X_val, y_val),\n",
    "                   equal_opportunity_score(sensitive_column=\"Sex\")(sols[i], X_val, y_val),\n",
    "                   p_percent_score(sensitive_column=\"Sex\")(sols[i], X_val),\n",
    "                   coefficient_of_variation(sols[i], X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding non-dominate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_models = []\n",
    "metrics_selected = []\n",
    "for i in range(len(sols)):\n",
    "    flag = True\n",
    "    for j in range(len(sols)):\n",
    "        if i != j:\n",
    "            dom = dominate(metrics[j], metrics[i])\n",
    "            if dom:\n",
    "                flag = False\n",
    "                break\n",
    "    if flag:\n",
    "        metrics_selected+=[metrics[i]]\n",
    "        par_models.append((\"Model \"+str(i), sols[i]))\n",
    "metrics_selected = pd.DataFrame(metrics_selected, columns=['Acc', 'Eq Opor', 'P Perc', 'Coev Var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning methods with too low performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(data, percentile):\n",
    "    size = len(data)\n",
    "    return sorted(data)[int(math.ceil((size * percentile) / 100)) - 1]\n",
    "\n",
    "all_idx = set(metrics_selected.index)\n",
    "for metr, sign in zip(metrics_selected, [1, 1, 1, -1]):\n",
    "    if sign>0:\n",
    "        perc = percentile(metrics_selected[metr], 10)\n",
    "        all_idx = all_idx.intersection(np.where(metrics_selected[metr]>=perc)[0])\n",
    "    else:\n",
    "        perc = percentile(metrics_selected[metr], 90)\n",
    "        all_idx = all_idx.intersection(np.where(metrics_selected[metr]<=perc)[0])\n",
    "        \n",
    "par_models_clean = [model for idx, model in enumerate(par_models) if idx in all_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = []\n",
    "best_eq = []\n",
    "best_pp = []\n",
    "best_var = []\n",
    "best_acc_v = 0\n",
    "best_eq_v = 0\n",
    "best_pp_v = 0\n",
    "best_var_v = 100\n",
    "\n",
    "for s, model in par_models_clean:\n",
    "    if model.score(X_val, y_val) > best_acc_v:\n",
    "        best_acc_v = model.score(X_val, y_val)\n",
    "        best_acc = [model, model.score(X_val, y_val),\n",
    "                   equal_opportunity_score(sensitive_column=\"Sex\")(model, X_val, y_val),\n",
    "                   p_percent_score(sensitive_column=\"Sex\")(model, X_val),\n",
    "                   coefficient_of_variation(model, X_val, y_val)]\n",
    "    if equal_opportunity_score(sensitive_column=\"Sex\")(model, X_val, y_val) > best_eq_v:\n",
    "        best_eq_v = equal_opportunity_score(sensitive_column=\"Sex\")(model, X_val, y_val)\n",
    "        best_eq = [model, model.score(X_val, y_val),\n",
    "                   equal_opportunity_score(sensitive_column=\"Sex\")(model, X_val, y_val),\n",
    "                   p_percent_score(sensitive_column=\"Sex\")(model, X_val),\n",
    "                   coefficient_of_variation(model, X_val, y_val)]\n",
    "    if p_percent_score(sensitive_column=\"Sex\")(model, X_val) > best_pp_v:\n",
    "        best_pp_v = p_percent_score(sensitive_column=\"Sex\")(model, X_val)\n",
    "        best_pp = [model, model.score(X_val, y_val),\n",
    "                   equal_opportunity_score(sensitive_column=\"Sex\")(model, X_val, y_val),\n",
    "                   p_percent_score(sensitive_column=\"Sex\")(model, X_val),\n",
    "                   coefficient_of_variation(model, X_val, y_val)]\n",
    "    if coefficient_of_variation(model, X_val, y_val) < best_var_v:\n",
    "        best_var_v = coefficient_of_variation(model, X_val, y_val) \n",
    "        best_var = [model, model.score(X_val, y_val),\n",
    "                   equal_opportunity_score(sensitive_column=\"Sex\")(model, X_val, y_val),\n",
    "                   p_percent_score(sensitive_column=\"Sex\")(model, X_val),\n",
    "                   coefficient_of_variation(model, X_val, y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=3.9222543584631597, class_weight=None, dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                    max_iter=10000, multi_class='multinomial', n_jobs=None,\n",
       "                    penalty='l2', random_state=None, solver='lbfgs',\n",
       "                    tol=4.504504504504503e-09, verbose=0, warm_start=False),\n",
       " 0.66,\n",
       " 0.9890109890109889,\n",
       " 0.936868686868687,\n",
       " 0.6647007305466981]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=3.9222543584631597, class_weight=None, dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                    max_iter=10000, multi_class='multinomial', n_jobs=None,\n",
       "                    penalty='l2', random_state=None, solver='lbfgs',\n",
       "                    tol=4.504504504504503e-09, verbose=0, warm_start=False),\n",
       " 0.66,\n",
       " 0.9890109890109889,\n",
       " 0.936868686868687,\n",
       " 0.6647007305466981]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=7.0061383517914555, class_weight=None, dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                    max_iter=10000, multi_class='multinomial', n_jobs=None,\n",
       "                    penalty='l2', random_state=None, solver='lbfgs',\n",
       "                    tol=4.504504504504505e-09, verbose=0, warm_start=False),\n",
       " 0.65,\n",
       " 0.96,\n",
       " 0.989010989010989,\n",
       " 0.7037571328799413]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=0.004603800144057659, class_weight=None, dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                    max_iter=10000, multi_class='multinomial', n_jobs=None,\n",
       "                    penalty='l2', random_state=None, solver='lbfgs',\n",
       "                    tol=4.5045045045045035e-09, verbose=0, warm_start=False),\n",
       " 0.66,\n",
       " 0.9333333333333333,\n",
       " 0.9494505494505494,\n",
       " 0.5222329678670933]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble - Non-Dominated Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf2 = SimpleVoting(estimators=par_models_clean, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eclf2 = eclf2.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics - Train Data\n",
      "Acc:  0.6531531531531531\n",
      "Eq Opor:  0.9323116219667943\n",
      "P Perc:  0.961690271650801\n",
      "Coev Var:  0.6675792642454637\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics - Train Data\")\n",
    "print(\"Acc: \", eclf2.score(X_train, y_train))\n",
    "print(\"Eq Opor: \", equal_opportunity_score(sensitive_column=\"Sex\")(eclf2, X_train, y_train))\n",
    "print(\"P Perc: \", p_percent_score(sensitive_column=\"Sex\")(eclf2, X_train))\n",
    "print(\"Coev Var: \", coefficient_of_variation(eclf2, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics - Validation Data\n",
      "Acc:  0.66\n",
      "Eq Opor:  0.9890109890109889\n",
      "P Perc:  0.8792270531400966\n",
      "Coev Var:  0.6647007305466981\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics - Validation Data\")\n",
    "print(\"Acc: \", eclf2.score(X_val, y_val))\n",
    "print(\"Eq Opor: \", equal_opportunity_score(sensitive_column=\"Sex\")(eclf2, X_val, y_val))\n",
    "print(\"P Perc: \", p_percent_score(sensitive_column=\"Sex\")(eclf2, X_val))\n",
    "print(\"Coev Var: \", coefficient_of_variation(eclf2, X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics - Test Data\n",
      "Acc:  0.625\n",
      "Eq Opor:  0.9323308270676691\n",
      "P Perc:  0.9807692307692308\n",
      "Coev Var:  0.6575103548402857\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics - Test Data\")\n",
    "print(\"Acc: \", eclf2.score(X_test, y_test))\n",
    "print(\"Eq Opor: \", equal_opportunity_score(sensitive_column=\"Sex\")(eclf2, X_test, y_test))\n",
    "print(\"P Perc: \", p_percent_score(sensitive_column=\"Sex\")(eclf2, X_test))\n",
    "print(\"Coev Var: \", coefficient_of_variation(eclf2, X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
